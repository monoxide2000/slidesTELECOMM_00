<!doctype html>
<html lang="es">

	<head>
		<meta charset="utf-8">

		<title>ACP-153 Telecomunicaciones</title>

		<meta name="description" content="InfoTheory - introCourse>
		<meta name="author" content="Julio Ramírez-Pacheco">

		<meta name="apple-mobile-web-app-capable" content="yes">
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/solarized.css" id="theme">
		<link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">


		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="lib/css/zenburn.css">
		<link href="https://fonts.googleapis.com/css?family=Pacifico" rel="stylesheet">
		<link href="https://fonts.googleapis.com/css2?family=Dancing+Script:wght@500&family=Kaushan+Script&display=swap" rel="stylesheet">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>
		<link rel="stylesheet" href="css/user.css">
		<!--[if lt IE 9]>
		<script src="lib/js/html5shiv.js"></script>
		<![endif]-->
	</head>

	<body>
		<div class="myLogo" style="background: url(img/logoUQRoo.png);
												position: absolute;
												bottom: 40px;
												right: 80px;
												width: 190px;
												height: 100px;
												background-size: cover;">
		</div>
		<div class="reveal">

			<!-- Any section element inside of this container is displayed as a slide -->
			<div class="slides">
				<section>
					<h1 style="font-family: 'Kaushan Script', cursive; font-size: 3.1em;"><span style="text-transform: capitalize;"><span>Telecomunicaciones</span></h1>
					<h3 style="font-family: 'Kaushan Script', cursive; font-size: 50px; text-transform: lowercase"><span style="text-transform: uppercase">T</span><span>eoría de la información</span></h3>
					<p style="font-family: 'Dancing Script', cursive;">
						<small>Dr. Julio César Ramírez-Pacheco </small>
					</p>
					<p style="font-size:1.5rem">Presentación en: <a style="color:lightblue;" href="https://monoxide2000.github.io/intro_infoTheory">https://monoxide2000.github.io/intro_infoTheory</a></p>

				</section>

				<section data-transition="zoom">
					<h2>Contenido</h2>
					<ul>
						<li class="fragment">Contenido de información.</li>
						<li class="fragment">Entropía de Shannon</li>
						<li class="fragment">Entropía conjunta y condicional</li>
						<li class="fragment">Información mutua.</li>
						<li class="fragment">Divergencia.</li>
						<li class="fragment">¿Preguntas?.</li>
					</ul>
				</section>

				<section data-transition="zoom">
					  <h2>Contenido de información</h2>
			      <ul>
			      	<li class="fragment">Las definiciones que siguen se basan en espacios de probabilidad con un un espacio muestral <span style= "color:#e76f51">$\Omega$</span>, eventos <span style= "color:#e76f51">$\mathcal{A}_i$</span> y medidas de probabilidad definidas en <span style= "color:#e76f51">$P(\mathcal{A}_i$)</span> <span style= "color:#2a9d8f" class="fragment">($0 \le P(\mathcal{A}_i) \le 1$ y $\sum_i{P(\mathcal{A}_i)}=1$)</span</li>
			      	<li class="fragment">De igual forma aplica a variables aleatorias discretas, <span style= "color:#e76f51">$X$</span>, con alfabeto <span style= "color:#e76f51">$\mathcal{X}$</span> y función de masa de probabilidad, <span style= "color:#e76f51">$p_X(k) = \mbox{Pr}(X=k)$</span> <span style= "color:#2a9d8f" class="fragment">($\sum_{k\in \mathcal{X}}{p_X(k)=1}$)</span>.</li>
			      </ul>
				</section>

				<section data-transition="zoom">
				      <h2>Contenido de informacion: cont.</h2>
							<div class="fragment">
										<div style="font-family: 'Pacifico';" class="def-block">
										Definición
										</div>
										<div class="def-block-eq">
										<p style="padding:0; margin:5px;">
											Sea $A$ un evento de un espacio de probabilidad con $P(A)\ne 0$, la cantidad de información de $A$ está definida como:
											$$<br>
											I(A)=	\log_D \left( \frac{1}{P(A)} \right)\\
											$$
											<br>
									  </div>
						  </div>
						<div class="fragment">
							<p>Donde $D$ es la base del logaritmo ($D=2$ resulta en bits)</p>
						</div>
					</section>

					<section data-transition="zoom">
					      <h2>Contenido de información: cont.</h2>
								<ul>
									<li class="fragment">Se puede notar que si <span style= "color:#e76f51">$P(A_1) \ge P(A_2)$</span>, entonces <span style= "color:#e76f51">$I(A_1) \le I(A_2)$</span></li>
									<li class="fragment">Además si $A_1$ y $A_2$ son eventos independientes <span style= "color:#e76f51">($P(A_1 \cap A_2)=P(A_1)P(A_2)$)</span> entonces se tiene que <span style= "color:#2a9d8f" class="fragment">$I(A_1\cap A_2)= I(A_1)+I(A_2)$</span></li>
                </ul>
						</section>


						<section data-transition="zoom">
						      <h2>Pérdida de información</h2>
									<div class="fragment">
												<div style="font-family: 'Pacifico';" class="def-block">
												Definición
												</div>
												<div class="def-block-eq">
												<p style="padding:0; margin:5px;">
													Sean $A$ y $B$ dos eventos, tal que $A \subset B$, entonces, la pérdida de información de $A$ usando la información de $B$ está dada por:
													$$L(A|B) = I(A)-I(B)=\log_D \frac{1}{P(A|B)}$$
												</p>
											  </div>
								  </div>
								<div class="fragment">
									<p>Donde $D$ es la base del logaritmo.</p>
								</div>
							</section>

						<section data-transition="zoom">
						      <h2>Entropía</h2>
									<div class="fragment">
												<div style="font-family: 'Pacifico';" class="def-block">
												Definición
												</div>
												<div class="def-block-eq">
													<p style="padding:0; margin:5px;">
														La entropía de una variable aleatoria $X$ con PMF $p(k)$ está definida como:
														$$H(X) = \sum_{k \in \mathcal{X}}{p(k)\log_D \frac{1}{p(k)}}$$
													</p>
													<br>
													<p class="fragment">También se denota la entropía como $H(p)$, $H_p$, $H(p_1,p_2, \ldots, p_n)$, etc.</p>
											  </div>
								  </div>
							</section>

					<section data-transition="zoom">
					      <h2>Entropía: continuación</h2>
								<ul>
									<li class="fragment">$H(X) = -\sum_{k\in \mathcal{X}}{p(k)\log p(k)}$</li>
									<li class="fragment">$H(X) \ge 0$ ya que $0\le p(k) \le 1$</li>
									<li class="fragment">$H_b(X) = \log_b(a)H_a(X)$</li>
								</ul>
						</section>

						<section data-transition="zoom">
						      <h2>Entropía: propiedades</h2>
									<ul>
										<li class="fragment">Simetría: $H(p_1, p_2, \ldots, p_n) = H(p_{k(1)}, p_{k(2)}, \ldots , p_{k(n)})$</li>
										<li class="fragment">Expansión: $H(p_1, p_2, \ldots, p_n) = H(0, p_1, p_2, \ldots, p_n)$</li>
										<li class="fragment">Aditividad: $H(p_1q_1, \ldots, p_1q_n,\ldots, p_mq_1, \ldots p_mq_n)$= $H(p_1, \ldots, p_m)+H(q_1, \ldots, q_n)$</li>
										<li class="fragment">Recursividad: $H(p_1, \ldots, p_n)=H(p_1+p_2,p_3, \ldots, p_n)+$$(p_1+p_2)H(\frac{p_1}{p_1+p_2}, \frac{p_2}{p_1+p_2})$</li>
									</ul>
							</section>


							<section data-transition="zoom", data-background-color="#edf6f9">
								<h2>Entropía: Bernoulli</h2>
								<p style ="text-align: left; font-size:0.8em;"> Sea $X$ una variable aleatoria con PMF:
								$$
								p_X(k) = \begin{cases}
								p & k=1\\
								(1-p)& k=0
								\end{cases}
								$$
								Calcular la entropía</p>
								<p class="fragment" style ="text-align: left; color:green; font-size:0.8em;"><span style="color: blue;">Solución:</span>
									Recordemos que $H(X) = -\sum_{k\in \mathcal{X}}p_k \log_D p_k$, por lo tanto:</p>
									<br>
                  <p style= "color:#e76f51; background-color: #e9edc9; font-size:0.8em;" class="fragment">
									$$
									\begin{align}
									H(X)  = -(1-p)\log_D(1-p)-p \log_D(p)\\
									\end{align}
									$$
								</p>

								</section>

								<section data-transition="zoom">
											<h2>Entropía: Bernoulli</h2>
											<img src="img/bernoulli.png" alt="Bernoulli entropy" style="width:80%;">

									</section>

									<section data-transition="zoom">
												<h2>Entropía: continuación</h2>
												<img src="img/pmfs.jpeg" alt="Binomial pms same entropy" style="width:50%;">

										</section>


									<section data-transition="zoom">
												<h2>Entropía diferencial</h2>
												<div class="fragment">
															<div style="font-family: 'Pacifico';" class="def-block">
															Definición
															</div>
															<div class="def-block-eq">
																<p style="padding:0; margin:5px;">
																	La entropía de una variable aleatoria continua $X$ con PDF $f(x)$ está definida como:
																	$$h(X) = \int_{-\infty}^{+\infty}{f(x)\log_D \frac{1}{f(x)}},$$
																</p>
																<br>
																<p class="fragment">donde D es el índice del logaritmo.</p>
															</div>
												</div>
										</section>


										<section data-transition="zoom", data-background-color="#edf6f9">
											<h2>$h(X)$: uniforme</h2>
											<p style ="text-align: left; font-size:0.8em;"> Sea $X$ una variable aleatoria con PDF:
											$$f(x) = \begin{cases}
                      \frac{1}{b-a} & a < x < b\\
                      0 & \mbox{en otro caso}
                      \end{cases}
                      $$
											Calcular la entropía diferencial</p>
											<p class="fragment" style ="text-align: left; color:green; font-size:0.8em;"><span style="color: blue;">Solución:</span>
												Recordemos que $h(X) = -\int_{-\infty}^{+\infty}{f(x) \log f(x)}$, por lo tanto:
												$$
												\begin{align}
                        h(X) = & -\int_{a}^b{\left(\frac{1}{b-a}\right) \log(\frac{1}{b-a}) \, dx} = \frac{\log(b-a)}{b-a}\int_a^b{dx}\\
                        = & \frac{\log(b-a)}{b-a}\times (b-a) = \log(b-a)\\
                        \end{align}
												$$
											</p>

											</section>


											<section data-transition="zoom">
														<h2>VA Uniforme: Var vs $h(X)$</h2>
														<img src="img/unif.svg" alt="Uniform RV entropy vs Var" style="width:80%;">

												</section>



						<section data-transition="zoom">
						      <h2>Entropía conjunta</h2>
									<div class="fragment">
												<div style="font-family: 'Pacifico';" class="def-block">
												Definición
												</div>
												<div class="def-block-eq">
												<p style="padding:0; margin:5px;">
													La entropía conjunta de dos variables aleatorias $X$ e $Y$ con pmf conjunta $p(x,y)$ está dada por:
													$$<br>
													H(X,Y)= -\sum_{x\in \mathcal{X}}\sum_{y \in \mathcal{Y}}{p(x,y) \log_D p(x,y)},
													$$
													<br>
													que también puede ser expresada como $H(X,Y)=-\mathbb{E}{\log p(X,Y)}$.
											</div>
								  </div>
							</section>


							<section data-transition="zoom">
							      <h2>Entropía condicional</h2>
										<div class="fragment">
													<div style="font-family: 'Pacifico';" class="def-block">
													Definición
													</div>
													<div class="def-block-eq">
													<p style="padding:0; margin:5px;">
														La entropía condicional de la variable aleatoria $Y$ dado $X$ con pmf conjunta $p(x,y)$ y pmf condicional $p(x|y)$ está definida como:
														$$<br>
														\begin{align}
														H(Y|X)= &\sum_{x\in \mathcal{X}}{p(x)H(Y|X=x)}\\
														 =&  \sum_{x\in \mathcal{X}}\sum_{y \in \mathcal{Y}}{p(x,y) \log_D \frac{1}{p(y|x)}},
														\end{align}
														$$
												</div>
									  </div>
								</section>


								<section data-transition="zoom" data-background-color="#edf6f9">
											<h2>Ejercicios</h2>
											<p class="fragment">Hallar $H(X), H(Y)$, $H(X,Y)$ y $H(X|Y)$ para:</p>
											<img class = "fragment" src="img/pmfconjunta.png" alt="Joint pmf exercise" style="width:80%;">

									</section>



									<section data-transition="zoom", data-background-color="#edf6f9">
										<h2>Ejercicios: continuación</h2>
										<p class="fragment" style ="text-align: left; color:green; font-size:0.7em;"><span style="color: blue;">Solución:</span>
											Recordemos que <span style= "color:#e76f51">$p(x) = \sum_{y \in \mathcal{Y}}p(x,y)$</span> y <span style= "color:#e76f51">$p(y) = \sum_{x \in \mathcal{X}}p(x,y)$</span>, por lo tanto:
											$$
											\begin{align}
											p(x=a) = & \sum_{j=a}^e{p(a,j)}=\frac{1}{10}+\frac{1}{20}+\frac{1}{40}+\frac{1}{80}+\frac{1}{80}=\frac{1}{5} \\
                      p(x=b) = & \sum_{j=a}^e{p(b,j)}=\frac{1}{20}+\frac{1}{40}+\frac{1}{80}+\frac{1}{80}+\frac{1}{10}=\frac{1}{5}\\
                      \vdots = & \vdots\\
											\end{align}
											$$
											<br />
											y <span style= "color:#e76f51">$p(x) = 1/5, x=a,b,c,d,e$</span>, por lo tanto <br />
											<span style= "color:#e76f51">$$H(X)=5\times \frac{1}{5}\log 5 = \log 5\, \mbox{bits} = H(Y)$$</span>
										</p>

										</section>

										<section data-transition="zoom", data-background-color="#edf6f9">
											<h2>Ejercicios: continuación</h2>
											<p class="fragment" style ="text-align: left; color:green; font-size:0.7em;"><span style="color: blue;">Solución:</span>
											  ahora calculamos <span style= "color:#e76f51">$p(x,y)$</span> y obtenemos:
												$$
												\begin{align}
												H(X,Y) = & \sum_{x\in\mathcal{X}}\sum_{y \in \mathcal{Y}}{p(x,y)\log p(x,y)} \\
	                      H(X,Y) = & -5 \left[ \frac{1}{10}\log \frac{1}{10}+\frac{1}{20}\log \frac{1}{20}+\frac{1}{40}\log \frac{1}{40}+\frac{1}{80}\log \frac{1}{80}+\frac{1}{80}\log \frac{1}{80}\right]\\
												H(X,Y) = & \log 5 + \left[ \frac{1}{2}\log \frac{1}{2}+\frac{1}{4}\log \frac{1}{4}+\frac{1}{8}\log \frac{1}{8}+\frac{1}{16}\log \frac{1}{16}+\frac{1}{16}\log \frac{1}{16}\right]\\
												H(X,Y) = & \log5 + \frac{5}{8} \, \, \mbox{bits}
												\end{align}
												$$

											</p>

											</section>

											<section data-transition="zoom" data-background-color="#edf6f9">
														<h2>Ejercicios</h2>
														<p class="fragment">Ahora calculamos $p(x|y)=p(x,y)/p(y)$, e.g: <span class="fragment" style="color:#e76f51">$p(a|b)=p(x=a,y=b)/p(y=b)=(1/20)/(1/5)=1/4$</span></p>
														<img class = "fragment" src="img/pmfcondicional.png" alt="Joint pmf exercise" style="width:80%;">

												</section>



											<section data-transition="zoom", data-background-color="#edf6f9">
												<h2>Ejercicios: continuación</h2>
												<p class="fragment" style ="text-align: left; color:green; font-size:0.7em;"><span style="color: blue;">Solución:</span>
												  ahora calculamos <span style= "color:#e76f51">$H(X|Y)$</span> y obtenemos:
													$$
													\begin{align}
													H(X|Y) = & \sum_{y \in \mathcal{y}}{p(y)H(X|Y=a,b,c,d,e)} \\
		                      H(X|Y) = & 5 \frac{1}{5} \left[ H(\frac{1}{2},\frac{1}{4},\frac{1}{8},\frac{1}{16}, \frac{1}{16}) \right]\\
													H(X|Y) = & H(\frac{1}{2},\frac{1}{4},\frac{1}{8},\frac{1}{16},\frac{1}{16})\\
													H(X|Y) = & \frac{15}{8} \, \, \mbox{bits} \\
													\end{align}
													$$

												</p>

												</section>

												<section data-transition="zoom" data-background-color="#edf6f9">
															<h2>Ejercicios: su turno</h2>
															<p class="fragment">Hallar $H(X), H(Y)$, $H(X,Y)$ y $H(X|Y)$ para:</p>
															<img class = "fragment" src="img/ejercicio.png" alt="Joint pmf exercise 2" style="width:60%;">

													</section>



							<section data-transition="zoom">
										<h2>Propiedades de $H(X,Y)$ y $H(Y|X)$</h2>
										<ul>
											<li class="fragment">$H(X,Y) = H(Y,X)$</li>
											<li class="fragment">$H(X,Y)\ge 0, \, H(X|Y)\ge 0, \, H(Y|X)\ge 0$</li>
											<li class="fragment">$H(X|Y)=H(X,Y)-H(Y)$</li>
											<li class="fragment">$H(X,Y)\ge H(Y)$</li>
											<li class="fragment">$H(X,Y) \le H(X)+H(Y)$</li>
											<li class="fragment">$H(X|Y) \le H(X)$</li>
										</ul>
								</section>

								<section data-transition="zoom">
											<h2>Información relativa</h2>
											<div class="fragment">
														<div style="font-family: 'Pacifico';" class="def-block">
														Definición
														</div>
														<div class="def-block-eq">
														<p style="padding:0; margin:5px;">
															La información relativa o distancia de Kullback-Leibler entre dos pmfs $p(x)$ y $q(x)$ está definida como:
															$$<br>
															D(p||q) = \sum_{x \in \mathcal{X}}{p(x)\log_D \frac{p(x)}{q(x)}}
															$$
															<br>
															$D(p||q)= E_p \log \frac{p(x)}{q(x)}$. Se asume que $0\log\frac{0}{0}=0$, $0 \log \frac{0}{q}=0$ y $p\log \frac{p}{0}=\infty$.
													</div>
											</div>
									</section>


									<section data-transition="zoom">
												<h2>Información mutua</h2>
												<div class="fragment">
															<div style="font-family: 'Pacifico';" class="def-block">
															Definición
															</div>
															<div class="def-block-eq">
															<p style="padding:0; margin:5px;">
																Sean $X$ e $Y$ dos VAs con pmf $p(x,y)$ y pmf marginal $p(x)$ y $p(y)$, la información mutua se define como:
																$$
																\begin{align}
																I(X;Y) = &\sum_{x \in \mathcal{X}}\sum_{x \in \mathcal{X}}{p(x,y)\log_D \frac{p(x,y)}{p(x)q(x)}}\\
																=& D(p(x,y)||p(x)p(y))\\
																=& E_{p(x,y)}\log \frac{p(X,Y)}{p(X)p(Y)}
																\end{align}
																$$

														</div>
												</div>
										</section>

									<section data-transition="zoom">
												<h2>Propiedades de la información mutua</h2>
												<ul>
													<li class="fragment">$I(X;Y)=I(Y;X)$</li>
													<li class="fragment">$I(X;Y)=H(X)-H(X|Y)$</li>
													<li class="fragment">$I(X;Y)=H(Y)-H(Y|X)$</li>
													<li class="fragment">$I(X;X)= H(X)$</li>
													<li class="fragment">$I(X;X)\ge 0$</li>
													<li class="fragment">$I(X;Y)= H(X)+H(Y)-H(X,Y)$</li>
												</ul>
										</section>




				<section data-transition="zoom", data-background-color="#edf6f9">
					<h2>Ejemplo: entropia relativa</h2>
					<p style ="text-align: left; font-size:0.8em;"> La entropía relativa diferencial de dos variables aleatorias normales $f(x)=\mathcal{N}(\mu_1, \sigma_1^2)$ y $g(x)=\mathcal{N}(\mu_2, \sigma_2^2)$ está dada por:
					<p class="fragment" style ="text-align: left; color:green; font-size:0.7em;">
						$D(f||g)=\int_{-\infty}^{+\infty}{f(x)\log \frac{f(x)}{g(x)}}$, por lo tanto:<br>
						$$
						\begin{align}
						D(f||g)  = & \int{\mathcal{N}(\mu_1,\sigma_1^2) \log \frac{\mathcal{N}(\mu_1,\sigma_1^2)}{\mathcal{N}(\mu_1,\sigma_1^2)}}\\
						D(f||g)  =& \frac{1}{2}\log \mbox{e}\left( \ln(\frac{\sigma_2^2}{\sigma_1^2})+\frac{\sigma_1^2}{\sigma_2^2}+\frac{(\mu_1-\mu_2)^2}{\sigma_2^2}-1 \right)\\
						D(f||g)  = & \frac{1}{2}\mu_2^2 \log \mbox{e} \, \, \, \mbox{cuando} \, \sigma_1=\sigma_2=1 \, \, \mbox{y} \, \, \mu_1=0\\
						D(f||g)  = & \frac{1}{2} \log \mbox{e}\left(\ln(\sigma_2^2)+\frac{1}{\sigma_2^2}-1 \right) \, \, \, \mbox{cuando} \, \mu_1=\mu_2 \, \, \mbox{y} \, \, \sigma_1=1
						\end{align}
            $$
					</p>
					</section>


					<section data-transition="zoom", data-background-color="#edf6f9">
						<h2>Ejemplo: $D(f||g)$</h2>
						<img class = "fragment" src="img/diff1.svg" alt="Relative entropy" style="width:80%;">
				</section>


				<section data-transition="zoom", data-background-color="#edf6f9">
					<h2>Ejemplo: $D(f||g)$</h2>
					<img class = "fragment" src="img/diff2.svg" alt="Relative entropy" style="width:80%;">
			</section>

			<section data-transition="zoom", data-background-color="#edf6f9">
				<h2>Referencias</h2>
				<ul>
					<li>Cover, T. M. (1999). Elements of information theory. John Wiley & Sons.</li>
					<li>Eshima, N. (2020). Statistical Data Analysis and Entropy. Springer Singapore.</li>
				</ul>

			</section>


				<section>
					<h2>¿Preguntas?</h2>
				</section>










			</div>

		</div>
		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.js"></script>

		<script>

			// More info https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				controls: true,
				progress: true,
				history: true,
				center: true,

				transition: 'slide', // none/fade/slide/convex/concave/zoom
				math: {
					//	mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
					config: 'TeX-AMS_HTML-full'
				},

				menu: {
		// Specifies which side of the presentation the menu will
		// be shown. Use 'left' or 'right'.
		side: 'left',

		// Add slide numbers to the titles in the slide list.
		// Use 'true' or format string (same as reveal.js slide numbers)
		numbers: false,

		// Specifies which slide elements will be used for generating
		// the slide titles in the menu. The default selects the first
		// heading element found in the slide, but you can specify any
		// valid css selector and the text from the first matching
		// element will be used.
		// Note: that a section data-menu-title attribute or an element
		// with a menu-title class will take precedence over this option
		titleSelector: 'h1, h2, h3, h4, h5, h6',

		// If slides do not have a matching title, attempt to use the
		// start of the text content as the title instead
		useTextContentForMissingTitles: false,

		// Hide slides from the menu that do not have a title.
		// Set to 'true' to only list slides with titles.
		hideMissingTitles: false,

		// Adds markers to the slide titles to indicate the
		// progress through the presentation. Set to 'false'
		// to hide the markers.
		markers: true,

		// Specify custom panels to be included in the menu, by
		// providing an array of objects with 'title', 'icon'
		// properties, and either a 'src' or 'content' property.
		custom: false,

		// Specifies the themes that will be available in the themes
		// menu panel. Set to 'true' to show the themes menu panel
		// with the default themes list. Alternatively, provide an
		// array to specify the themes to make available in the
		// themes menu panel, for example...
		// [
		//     { name: 'Black', theme: 'css/theme/black.css' },
		//     { name: 'White', theme: 'css/theme/white.css' },
		//     { name: 'League', theme: 'css/theme/league.css' }
		// ]
		themes: false,

		// Specifies the path to the default theme files. If your
		// presentation uses a different path to the standard reveal
		// layout then you need to provide this option, but only
		// when 'themes' is set to 'true'. If you provide your own
		// list of themes or 'themes' is set to 'false' the
		// 'themesPath' option is ignored.
		themesPath: 'css/theme/',

		// Specifies if the transitions menu panel will be shown.
		// Set to 'true' to show the transitions menu panel with
		// the default transitions list. Alternatively, provide an
		// array to specify the transitions to make available in
		// the transitions panel, for example...
		// ['None', 'Fade', 'Slide']
		transitions: false,

		// Adds a menu button to the slides to open the menu panel.
		// Set to 'false' to hide the button.
		openButton: true,

		// If 'true' allows the slide number in the presentation to
		// open the menu panel. The reveal.js slideNumber option must
		// be displayed for this to take effect
		openSlideNumber: false,

		// If true allows the user to open and navigate the menu using
		// the keyboard. Standard keyboard interaction with reveal
		// will be disabled while the menu is open.
		keyboard: true,

		// Normally the menu will close on user actions such as
		// selecting a menu item, or clicking the presentation area.
		// If 'true', the sticky option will leave the menu open
		// until it is explicitly closed, that is, using the close
		// button or pressing the ESC or m key (when the keyboard
		// interaction option is enabled).
		sticky: false,

		// If 'true' standard menu items will be automatically opened
		// when navigating using the keyboard. Note: this only takes
		// effect when both the 'keyboard' and 'sticky' options are enabled.
		autoOpen: true,

		// If 'true' the menu will not be created until it is explicitly
		// requested by calling RevealMenu.init(). Note this will delay
		// the creation of all menu panels, including custom panels, and
		// the menu button.
		delayInit: false,

		// If 'true' the menu will be shown when the menu is initialised.
		openOnInit: false,

		// By default the menu will load it's own font-awesome library
		// icons. If your presentation needs to load a different
		// font-awesome library the 'loadIcons' option can be set to false
		// and the menu will not attempt to load the font-awesome library.
		loadIcons: true
	},

				// More info https://github.com/hakimel/reveal.js#dependencies
				dependencies: [
					{ src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
					{ src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
					{ src: 'plugin/search/search.js', async: true },
					{ src: 'plugin/zoom-js/zoom.js', async: true },
					{ src: 'plugin/math/math.js', async: true },
					{src: 'plugin/menu/menu.js'},
					//{ src: 'plugin/katex/katex.js', async: true},
					//{ src: '../math-katex/math-katex.js', async: true },
					{ src: 'plugin/notes/notes.js', async: true }
				]
			});

			// JulioCRDev   slideshow
			var slideIndex = 1;
showDivs(slideIndex);

function plusDivs(n) {
  showDivs(slideIndex += n);
}

function currentDiv(n) {
  showDivs(slideIndex = n);
}

function showDivs(n) {
  var i;
  var x = document.getElementsByClassName("mySlides");
  var dots = document.getElementsByClassName("demo");
  if (n > x.length) {slideIndex = 1}
  if (n < 1) {slideIndex = x.length}
  for (i = 0; i < x.length; i++) {
     x[i].style.display = "none";
  }
  for (i = 0; i < dots.length; i++) {
     dots[i].className = dots[i].className.replace(" w3-white", "");
  }
  x[slideIndex-1].style.display = "block";
  dots[slideIndex-1].className += " w3-white";
}


var myIndex = 0;
carousel();

function carousel() {
    var i;
    var x = document.getElementsByClassName("mySlides");
    for (i = 0; i < x.length; i++) {
       x[i].style.display = "none";
    }
    myIndex++;
    if (myIndex > x.length) {myIndex = 1}
    x[myIndex-1].style.display = "block";
    setTimeout(carousel, 2000);
}

		</script>

	</body>
</html>
